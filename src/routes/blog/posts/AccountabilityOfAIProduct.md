---
title: 'How to make AI companies pay their fair share'
date: '2026-01-08'
tags: ['AI', 'Opinion']
shortDescription: 'A few bonker ideas to make AI fair'
---

Recently based on how much AI has been shoved down our throats, and seeing my electricity bill is expected to go by a 4 whole dollars per SDGE price raise that is probably due to AI, I am starting to wonder what are "possible" ways to make AI companies pay the price for these inconveniences they introduce in the name of the grand promise of AGI (which I can go into a whole debate on why it is not as exciting as AI companies claims).

Just to be clear, by AI companies, I don't mean all companies that are developing AI, but specifically frontier labs that uses AGI in their banner and serving chatbots, vibe coding platform, such as the CloseAI, Anthropic, Google Deepmind, Meta AI, etc. I think there are legitimate use cases for deep learning application in field like medical imaging and ML-assisted design, but they also suffer from the giants gorging up all the resources and churn out slops.

This is a rant post, don't expect coherence from it.

# End users should be able to sue AI companies for damages caused by their products

If you hire an employee and the person screws up big time, you fire them, and in some case you sue them for damage as well. Now somehow the AI companies convince at least a dozen of C-suite executives using their AI products are going to save money in the long run, and these executives just go stomp the ground a bit whenever a diasaster happens.

Worse, there are already numerous cases of AI products leading to self-harm in the real world. How is this not regulated yet? I know these AI companies have legal teams to fight their battle and lobbying firms to influence the lawmakers. And in some sense, it is indeed the user's fault, as there is a limit we can shift the blame to tool builders (Selling axes for chopping wood is completely legit, but there is no way oen can stop people from misusing the tool.).

And I think the fact that AI companies are still using legal team and traditional resource to defend against lawsuit and avoiding accountability is a strong signal to me that they are not that confident in their AI yet, despite all the magic claims.
I am totally down to held responsible for the sun not raising from the East and setting in the West, because I know that reality is so far away that I will not worry about it. But for AI, apparently they have not reached the same level of confidence yet, that's why they have to use all these legal clauses to protect themselves.

In other word, when one day an AI company comes out with a slogan along the line: "Feel free to sue us if our product causes you any damage", I will start to believe that the AI product is mature enough for general consumption.

# AI products should pay the "road fee"

One of the beloved CSS packages, tailwindcss, [couldn't afford to pay and forced to layoff 3 out of 4 people on their dev team,](https://github.com/tailwindlabs/tailwindcss.com/pull/2388#issuecomment-3717222957) despite being more popular than ever. This is at least partially due to AI chatbots are getting good enough to generate tailwindcss, and people no longer need to pay for the optional premium tailcss features. This is pretty tragic, especially I still enjoy going to tailwindcss documentation site and doing things my way. We can only expect AI is going to affect more and more open source projects like tailwind in the future.

Obviously companies have gone through the debates on copy right, IP, and license to use already, and unfortunately I don't think pursuing legal actions against AI companies is going to be successful. So instead of putting my faith in the legal system, I am more inclined toward some still-magical solution that is economy based. Imagine using [preplexity](https://www.perplexity.ai/), every time it generates content related to tailwindcss, it should pay a small fee to tailwindcss project, wouldn't that be great? How do we get AI companies to agree to do that is beyond me, but at least if this can be achieved, this may compensate people behind the training material. In the end, maybe built-in [paywall](https://github.com/coinbase/x402) is the solution to this problem.
The web used to be free, until someone exploits it too much.

# I am curious what Google and Meta are thinking about ad

One mystery on my mind these days is how companies that depend on ads to make money like Google and Meta are going to amortize the lost of revenue from Ads due to AI chatbots. I have been using Preplexity and Gemini for looking up information lately, and I haven't really seen any ads as I would usually do.
This must hurts the revenue of these companies, right? (Not my view in particular, but millions of daily users). This means either the use of AI chatbots is not as prevalent as they want us to believe, or Ads metric are not as effective as they used to be marketed to businesses.
Especially considering all of these chatbots offer free tier that are frankly quite sufficient for the general public, I cannot imagine the few whales going ham on API calls or paying for the 200 dollars subscription can recoup the lost of revenue from Ads.

Does this mean in the future these chatbots will start to shove Ads down our throats? If that happens, it is a matter of time for someone to put together a good enough local interface that does not show ads, which is 90% here already. Companies like CloseAI and Anthropic may not care as much, but this means Google and Meta are more likely to react in a way that works for consumers better, since their revenue depends on it.

# A semi-realistic solution: self host everything!

As mentioned in [my previous post](https://www.kazewong.io/blog/TheBadAGIBusiness), the one scenario that AI companies desperately trying to avoid is the widespread adoption of open source models and self-hosted services. And as a consumer I think self-hosting is where we should head to. One major problem is the majority of society is not tech-savy people, so I think there is actually a market opportunity to sell people AI-in-a-box solution, in case they want to use it. It needs to "applicance-tize" useful AI functionality, and offer them in a consumer-friendly way, just like the early day apple that a normie can set it up and go to town with it in less than 5 minutes. It should not be subscription-based product, and should be able to function completely offline. In some sense, the move from cloud to edge is somewhat align with this direction, minus the subscription part.

I work in machine learning and AI, obviously I am not fundamentally against entrepreneur building good AI products and make a profit on that. However, I think frontier labs get away with too much exploitation and is too aggresive on their All-in-or-nothing approach. I think it is time to make them pay their fair share. Relying on legal system is not likely to work in my opinion, so as a consumer and developer, I think we have to think outside of the box a bit to see how we can combat this AI epidemic we are facing.
